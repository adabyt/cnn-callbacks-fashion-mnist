# ğŸ‘• CNN with MobileNetV2 & Keras Callbacks on Fashion MNIST

This project demonstrates how to use **MobileNetV2** as a feature extractor for the **Fashion MNIST** dataset, combining **transfer learning** with a custom classification head.  
It also showcases the use of **Keras callbacks** â€” including **EarlyStopping**, **ModelCheckpoint**, and **TensorBoard** â€” to optimise training and track performance.

The modelâ€™s **best hyperparameters** (dense units, dropout, learning rate, optimiser) were sourced from prior hyperparameter tuning using **Random Search**, which can be found here: [cnn-keras-tuning-fashion-mnist](https://github.com/adabyt/cnn-keras-tuning-fashion-mnist).

---

## ğŸš€ Features
- Uses **MobileNetV2** pretrained on ImageNet for feature extraction  
- Adds a **custom dense layer & dropout** for Fashion MNIST classification  
- Implements **key Keras callbacks**:  
  - **EarlyStopping** â†’ stops training when validation loss stops improving  
  - **ModelCheckpoint** â†’ saves the best-performing model automatically  
  - **TensorBoard** â†’ visualises training curves, histograms, and more  
- Evaluates model performance across **multiple independent runs** to assess stability

---

## ğŸ“‚ Project Structure
```plaintext
cnn-callbacks-fashion-mnist/
â”‚
â”œâ”€â”€ callbacks_fashion_mnist.py   # Main training script
â”œâ”€â”€ saved_models/                # Best model saved as .keras
â”œâ”€â”€ logs/                        # TensorBoard logs
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ›  Installation & Setup

1ï¸âƒ£ **Clone the repo**
```bash
git clone https://github.com/adabyt/cnn-callbacks-fashion-mnist.git
cd cnn-callbacks-fashion-mnist
```

2ï¸âƒ£ **Install dependencies**
```bash
pip install -r requirements.txt
```

3ï¸âƒ£ **Run the script**
```bash
python callbacks_fashion_mnist.py
```

4ï¸âƒ£ **Launch TensorBoard (optional)**
```bash
tensorboard --logdir logs/fit
```
Then open [http://localhost:6006](http://localhost:6006) to visualise training.

---

## ğŸ“Š Model Summary
The final model structure:

- **MobileNetV2 (frozen)** â†’ feature extraction  
- **Global Average Pooling**  
- **Dense (480 units, ReLU)**  
- **Dropout (0.3)**  
- **Dense (10 units, Softmax)**  

_Total trainable parameters: ~619k (MobileNetV2 frozen)_

---

## ğŸ“ˆ Results & Observations

### ğŸ” Performance Across Runs
The model was trained multiple times to evaluate run-to-run consistency:

| Run | Test Accuracy | Test Loss | Epochs Used |
|----:|--------------:|----------:|------------:|
|  1  | 0.9079        | 0.2543    | 16          |
|  2  | 0.9076        | 0.2590    | 17          |
|  3  | 0.9056        | 0.2559    | 17          |
|  4  | 0.9080        | 0.2534    | 17          |
|  5  | 0.9065        | 0.2555    | 17          |
|  6  | 0.9052        | 0.2583    | 14          |

**Overall Performance:**  
**\`0.9068 Â± 0.0011\`** after 6 runs.

---

### ğŸ“Œ Why do results vary per run?

1. **Shuffle order** â€“ Different batch orders change weight updates.  
2. **Weight initialisation** â€“ Initial weights differ unless a seed is fixed.  
3. **Dropout randomness** â€“ Different neurons drop each epoch.  
4. **Adam optimiserâ€™s internal state** â€“ Tracks moving averages of gradients, which evolve differently per run.  
5. **GPU non-determinism** (less likely for smaller models) â€“ Minor floating-point differences can accumulate.

---

### ğŸ“‰ Signs of Overfitting
The logs suggest mild overfitting: training accuracy improved faster than validation accuracy.

**Ways to mitigate overfitting:**
- Add more data  
- Use data augmentation  
- Apply regularization (L1/L2)  
- Increase dropout  
- Rely on early stopping  
- Add batch normalisation  
- Simplify model architecture  
- Tune hyperparameters further  

---

## ğŸ Conclusion

This project shows how:
- **Transfer learning with MobileNetV2** can effectively classify Fashion MNIST with minimal training time.  
- **Callbacks** like EarlyStopping and ModelCheckpoint prevent overtraining and save the best model automatically.  
- **TensorBoard** provides invaluable visualisation for debugging and performance tracking.  

**Final test accuracy: ~90.7%.**
